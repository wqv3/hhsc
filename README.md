# hhsc

a simple http header scraper built with puppeteer. each session creates a folder and stores outgoing http request headers as individual `.txt` files.

## ğŸ“¦ features

- intercepts all outgoing http requests  
- logs and saves request headers  
- creates a new `session_x` folder per run  
- stores each request in a separate `request_x.txt` file  

## ğŸš€ usage

### install dependencies

```bash
npm install puppeteer
```

### run the scraper

```bash
node index.js
```

> right in hhsc/ folder.

## ğŸ—‚ output structure

```
sessions/
  â””â”€â”€ session_1/
        â”œâ”€â”€ request_1.txt
        â”œâ”€â”€ request_2.txt
        â””â”€â”€ ...
  â””â”€â”€ session_2/
        â””â”€â”€ ...
```

each `.txt` file contains:

```
â¡ï¸ request to: <url>

headers:
{
  "user-agent": "...",
  "accept": "...",
  ...
}
```

## âš™ï¸ configuration

set up:

```js
await page.goto('url', { waitUntil: 'networkidle2' });
```

-> 'url'` with yours.
